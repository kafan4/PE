"""
Script de Comparaison d'Hyperparam√®tres pour Transformer Encodeur-D√©codeur CSI
Effectue des apprentissages plus courts avec diff√©rentes configurations de param√®tres
et compare les performances sur 20 ex√©cutions pour chaque configuration.

Param√®tres test√©s:
- Nombre de t√™tes d'attention (NUM_HEADS)
- Nombre de couches encodeur (NUM_ENCODER_LAYERS)
- Nombre de couches d√©codeur (NUM_DECODER_LAYERS)

Auteur: Assistant IA
Date: Janvier 2026
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
import os
import json
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

# Importer les classes du script principal
from Transformer_Encoder_Decoder_CSI import (
    Config, TransformerEncoderDecoder, load_csi_data, 
    preprocess_csi_data, TransformerLRSchedule
)


# =============================================================================
# Configuration des Exp√©riences
# =============================================================================

class ExperimentConfig:
    """Configuration pour les exp√©riences d'hyperparam√®tres"""
    
    # Param√®tres fixes
    SEQUENCE_LENGTH = 300
    NUM_FEATURES = 52
    NUM_CLASSES = 7
    
    # Architecture Transformer (r√©duite pour acc√©l√©rer)
    D_MODEL = 64  # R√©duit de 128 √† 64
    DFF = 256  # R√©duit de 512 √† 256
    DROPOUT_RATE = 0.1
    
    # Entra√Ænement r√©duit pour acc√©l√©rer les exp√©riences (objectif: 1 heure totale)
    BATCH_SIZE = 64  # Augment√© pour acc√©l√©rer
    EPOCHS = 15  # R√©duit drastiquement
    LEARNING_RATE = 1e-4
    WARMUP_STEPS = 500  # R√©duit drastiquement
    
    # Param√®tres d'exp√©rimentation
    NUM_RUNS_PER_CONFIG = 5  # R√©duit de 20 √† 5 pour gagner du temps
    
    # Configurations √† tester (r√©duites)
    ATTENTION_HEADS = [4, 8]  # Seulement 2 configurations au lieu de 4
    ENCODER_LAYERS = [2, 4]   # Seulement 2 configurations au lieu de 4
    DECODER_LAYERS = [2, 4]   # Seulement 2 configurations au lieu de 4
    
    ACTIVITIES = ['bend', 'fall', 'lie down', 'run', 'sitdown', 'standup', 'walk']


# =============================================================================
# Fonctions Utilitaires
# =============================================================================

def create_config_variant(base_config, num_heads=None, num_encoder=None, num_decoder=None):
    """Cr√©e une variante de configuration avec des param√®tres modifi√©s"""
    config = Config()
    
    # Copier les param√®tres de base
    config.SEQUENCE_LENGTH = base_config.SEQUENCE_LENGTH
    config.NUM_FEATURES = base_config.NUM_FEATURES
    config.NUM_CLASSES = base_config.NUM_CLASSES
    config.D_MODEL = base_config.D_MODEL
    config.DFF = base_config.DFF
    config.DROPOUT_RATE = base_config.DROPOUT_RATE
    config.BATCH_SIZE = base_config.BATCH_SIZE
    config.EPOCHS = base_config.EPOCHS
    config.LEARNING_RATE = base_config.LEARNING_RATE
    config.WARMUP_STEPS = base_config.WARMUP_STEPS
    config.ACTIVITIES = base_config.ACTIVITIES
    
    # Appliquer les modifications
    config.NUM_HEADS = num_heads if num_heads is not None else 8
    config.NUM_ENCODER_LAYERS = num_encoder if num_encoder is not None else 4
    config.NUM_DECODER_LAYERS = num_decoder if num_decoder is not None else 4
    
    return config


def create_and_compile_model(config):
    """Cr√©e et compile un mod√®le avec la configuration donn√©e"""
    model = TransformerEncoderDecoder(config)
    
    # Learning rate schedule
    lr_schedule = TransformerLRSchedule(config.D_MODEL, config.WARMUP_STEPS)
    
    optimizer = keras.optimizers.Adam(
        learning_rate=lr_schedule,
        beta_1=0.9,
        beta_2=0.98,
        epsilon=1e-9
    )
    
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model


def train_single_run(config, X_train, y_train, X_val, y_val, run_number, config_name, verbose=0):
    """
    Effectue une seule ex√©cution d'entra√Ænement
    
    Args:
        config: Configuration du mod√®le
        X_train, y_train: Donn√©es d'entra√Ænement
        X_val, y_val: Donn√©es de validation
        run_number: Num√©ro de l'ex√©cution
        config_name: Nom de la configuration
        verbose: Niveau de verbosit√©
    
    Returns:
        dict: R√©sultats de l'entra√Ænement
    """
    print(f"  Run {run_number + 1}/5: ", end='', flush=True)
    
    # Cr√©er le mod√®le
    model = create_and_compile_model(config)
    
    # Build le mod√®le
    _ = model(X_train[:1])
    
    # Callbacks
    early_stopping = keras.callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=5,  # R√©duit pour acc√©l√©rer (stop si pas d'am√©lioration en 5 epochs)
        restore_best_weights=True,
        verbose=0
    )
    
    # Entra√Ænement
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=config.EPOCHS,
        batch_size=config.BATCH_SIZE,
        callbacks=[early_stopping],
        verbose=verbose
    )
    
    # √âvaluation finale
    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
    
    # Nombre d'√©poques effectu√©es
    epochs_trained = len(history.history['loss'])
    
    print(f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Epochs: {epochs_trained}")
    
    return {
        'config_name': config_name,
        'run_number': run_number,
        'num_heads': config.NUM_HEADS,
        'num_encoder_layers': config.NUM_ENCODER_LAYERS,
        'num_decoder_layers': config.NUM_DECODER_LAYERS,
        'train_accuracy': train_acc,
        'train_loss': train_loss,
        'val_accuracy': val_acc,
        'val_loss': val_loss,
        'epochs_trained': epochs_trained,
        'final_train_history': history.history
    }


# =============================================================================
# Exp√©rience 1: Variation du Nombre de T√™tes d'Attention
# =============================================================================

def experiment_attention_heads(base_config, X_train, y_train, X_val, y_val, results_dir):
    """
    Teste diff√©rents nombres de t√™tes d'attention
    """
    print("\n" + "="*80)
    print("EXP√âRIENCE 1: VARIATION DU NOMBRE DE T√äTES D'ATTENTION")
    print("="*80)
    
    results = []
    
    for num_heads in base_config.ATTENTION_HEADS:
        print(f"\nüîß Configuration: {num_heads} t√™tes d'attention")
        
        # V√©rifier que d_model est divisible par num_heads
        if base_config.D_MODEL % num_heads != 0:
            print(f"‚ö†Ô∏è Attention: D_MODEL ({base_config.D_MODEL}) n'est pas divisible par {num_heads}")
            print(f"   Ajustement de D_MODEL √† {(base_config.D_MODEL // num_heads) * num_heads}")
            temp_config = ExperimentConfig()
            temp_config.D_MODEL = (base_config.D_MODEL // num_heads) * num_heads
            config = create_config_variant(temp_config, num_heads=num_heads)
        else:
            config = create_config_variant(base_config, num_heads=num_heads)
        
        config_name = f"heads_{num_heads}"
        
        # Effectuer 5 runs
        for run in range(base_config.NUM_RUNS_PER_CONFIG):
            result = train_single_run(
                config, X_train, y_train, X_val, y_val, 
                run, config_name, verbose=0
            )
            results.append(result)
    
    # Sauvegarder les r√©sultats
    df = pd.DataFrame(results)
    df.to_csv(os.path.join(results_dir, 'experiment_1_attention_heads.csv'), index=False)
    
    return results


# =============================================================================
# Exp√©rience 2: Variation du Nombre de Couches Encodeur
# =============================================================================

def experiment_encoder_layers(base_config, X_train, y_train, X_val, y_val, results_dir):
    """
    Teste diff√©rents nombres de couches encodeur
    """
    print("\n" + "="*80)
    print("EXP√âRIENCE 2: VARIATION DU NOMBRE DE COUCHES ENCODEUR")
    print("="*80)
    
    results = []
    
    for num_layers in base_config.ENCODER_LAYERS:
        print(f"\nüîß Configuration: {num_layers} couches encodeur")
        
        config = create_config_variant(base_config, num_encoder=num_layers)
        config_name = f"encoder_{num_layers}"
        
        # Effectuer 5 runs
        for run in range(base_config.NUM_RUNS_PER_CONFIG):
            result = train_single_run(
                config, X_train, y_train, X_val, y_val, 
                run, config_name, verbose=0
            )
            results.append(result)
    
    # Sauvegarder les r√©sultats
    df = pd.DataFrame(results)
    df.to_csv(os.path.join(results_dir, 'experiment_2_encoder_layers.csv'), index=False)
    
    return results


# =============================================================================
# Exp√©rience 3: Variation du Nombre de Couches D√©codeur
# =============================================================================

def experiment_decoder_layers(base_config, X_train, y_train, X_val, y_val, results_dir):
    """
    Teste diff√©rents nombres de couches d√©codeur
    """
    print("\n" + "="*80)
    print("EXP√âRIENCE 3: VARIATION DU NOMBRE DE COUCHES D√âCODEUR")
    print("="*80)
    
    results = []
    
    for num_layers in base_config.DECODER_LAYERS:
        print(f"\nüîß Configuration: {num_layers} couches d√©codeur")
        
        config = create_config_variant(base_config, num_decoder=num_layers)
        config_name = f"decoder_{num_layers}"
        
        # Effectuer 5 runs
        for run in range(base_config.NUM_RUNS_PER_CONFIG):
            result = train_single_run(
                config, X_train, y_train, X_val, y_val, 
                run, config_name, verbose=0
            )
            results.append(result)
    
    # Sauvegarder les r√©sultats
    df = pd.DataFrame(results)
    df.to_csv(os.path.join(results_dir, 'experiment_3_decoder_layers.csv'), index=False)
    
    return results


# =============================================================================
# Analyse et Visualisation des R√©sultats
# =============================================================================

def analyze_and_visualize_results(results, experiment_name, param_name, results_dir):
    """
    Analyse et visualise les r√©sultats d'une exp√©rience
    
    Args:
        results: Liste des r√©sultats
        experiment_name: Nom de l'exp√©rience
        param_name: Nom du param√®tre test√©
        results_dir: R√©pertoire pour sauvegarder les visualisations
    """
    df = pd.DataFrame(results)
    
    # Calculer les statistiques par configuration
    if 'heads' in experiment_name:
        groupby_col = 'num_heads'
    elif 'encoder' in experiment_name:
        groupby_col = 'num_encoder_layers'
    else:
        groupby_col = 'num_decoder_layers'
    
    stats = df.groupby(groupby_col).agg({
        'val_accuracy': ['mean', 'std', 'min', 'max'],
        'train_accuracy': ['mean', 'std'],
        'epochs_trained': ['mean', 'std']
    }).round(4)
    
    print(f"\nüìä Statistiques pour {experiment_name}:")
    print(stats)
    
    # Sauvegarder les statistiques
    stats.to_csv(os.path.join(results_dir, f'{experiment_name}_statistics.csv'))
    
    # Visualisations
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Boxplot de la pr√©cision de validation
    ax1 = axes[0, 0]
    df.boxplot(column='val_accuracy', by=groupby_col, ax=ax1)
    ax1.set_title(f'Distribution de la Pr√©cision de Validation\n{param_name}')
    ax1.set_xlabel(param_name)
    ax1.set_ylabel('Pr√©cision de Validation')
    ax1.get_figure().suptitle('')  # Supprimer le titre auto-g√©n√©r√©
    
    # 2. Courbe de moyenne avec √©cart-type
    ax2 = axes[0, 1]
    grouped = df.groupby(groupby_col)['val_accuracy']
    means = grouped.mean()
    stds = grouped.std()
    param_values = means.index
    
    ax2.plot(param_values, means, 'o-', linewidth=2, markersize=8, label='Moyenne')
    ax2.fill_between(param_values, means - stds, means + stds, alpha=0.3, label='¬±1 √©cart-type')
    ax2.set_title(f'Pr√©cision Moyenne de Validation\n{param_name}')
    ax2.set_xlabel(param_name)
    ax2.set_ylabel('Pr√©cision de Validation')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. Comparaison Train vs Validation
    ax3 = axes[1, 0]
    train_means = df.groupby(groupby_col)['train_accuracy'].mean()
    val_means = df.groupby(groupby_col)['val_accuracy'].mean()
    
    x = np.arange(len(param_values))
    width = 0.35
    
    ax3.bar(x - width/2, train_means, width, label='Train', alpha=0.8)
    ax3.bar(x + width/2, val_means, width, label='Validation', alpha=0.8)
    ax3.set_title(f'Comparaison Train vs Validation\n{param_name}')
    ax3.set_xlabel(param_name)
    ax3.set_ylabel('Pr√©cision')
    ax3.set_xticks(x)
    ax3.set_xticklabels(param_values)
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')
    
    # 4. Nombre d'√©poques
    ax4 = axes[1, 1]
    epochs_means = df.groupby(groupby_col)['epochs_trained'].mean()
    epochs_stds = df.groupby(groupby_col)['epochs_trained'].std()
    
    ax4.bar(param_values, epochs_means, alpha=0.8, yerr=epochs_stds, capsize=5)
    ax4.set_title(f'Nombre Moyen d\'√âpoques\n{param_name}')
    ax4.set_xlabel(param_name)
    ax4.set_ylabel('√âpoques')
    ax4.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(os.path.join(results_dir, f'{experiment_name}_analysis.png'), dpi=150)
    plt.close()
    
    print(f"‚úÖ Visualisation sauvegard√©e: {experiment_name}_analysis.png")


def create_comparison_summary(results_dir):
    """
    Cr√©e un r√©sum√© comparatif de toutes les exp√©riences
    """
    print("\n" + "="*80)
    print("CR√âATION DU R√âSUM√â COMPARATIF")
    print("="*80)
    
    # Charger tous les r√©sultats
    exp1 = pd.read_csv(os.path.join(results_dir, 'experiment_1_attention_heads.csv'))
    exp2 = pd.read_csv(os.path.join(results_dir, 'experiment_2_encoder_layers.csv'))
    exp3 = pd.read_csv(os.path.join(results_dir, 'experiment_3_decoder_layers.csv'))
    
    # Statistiques pour chaque exp√©rience
    stats_exp1 = exp1.groupby('num_heads')['val_accuracy'].agg(['mean', 'std', 'max'])
    stats_exp2 = exp2.groupby('num_encoder_layers')['val_accuracy'].agg(['mean', 'std', 'max'])
    stats_exp3 = exp3.groupby('num_decoder_layers')['val_accuracy'].agg(['mean', 'std', 'max'])
    
    # Trouver les meilleures configurations
    best_heads = stats_exp1['mean'].idxmax()
    best_encoder = stats_exp2['mean'].idxmax()
    best_decoder = stats_exp3['mean'].idxmax()
    
    # Cr√©er le rapport
    summary = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'best_configurations': {
            'attention_heads': int(best_heads),
            'encoder_layers': int(best_encoder),
            'decoder_layers': int(best_decoder)
        },
        'best_accuracies': {
            'attention_heads': float(stats_exp1.loc[best_heads, 'mean']),
            'encoder_layers': float(stats_exp2.loc[best_encoder, 'mean']),
            'decoder_layers': float(stats_exp3.loc[best_decoder, 'mean'])
        },
        'all_statistics': {
            'attention_heads': stats_exp1.to_dict(),
            'encoder_layers': stats_exp2.to_dict(),
            'decoder_layers': stats_exp3.to_dict()
        }
    }
    
    # Sauvegarder le r√©sum√©
    with open(os.path.join(results_dir, 'summary_report.json'), 'w') as f:
        json.dump(summary, f, indent=4)
    
    # Afficher le r√©sum√©
    print("\nüìã MEILLEURES CONFIGURATIONS:")
    print(f"  ‚îú‚îÄ T√™tes d'attention: {best_heads} (accuracy: {summary['best_accuracies']['attention_heads']:.4f})")
    print(f"  ‚îú‚îÄ Couches encodeur: {best_encoder} (accuracy: {summary['best_accuracies']['encoder_layers']:.4f})")
    print(f"  ‚îî‚îÄ Couches d√©codeur: {best_decoder} (accuracy: {summary['best_accuracies']['decoder_layers']:.4f})")
    
    # Cr√©er une visualisation comparative
    fig, ax = plt.subplots(1, 3, figsize=(18, 5))
    
    # Exp√©rience 1
    stats_exp1['mean'].plot(kind='bar', ax=ax[0], yerr=stats_exp1['std'], capsize=5, alpha=0.8)
    ax[0].set_title('T√™tes d\'Attention\n(Moyenne ¬± √âcart-type)')
    ax[0].set_xlabel('Nombre de T√™tes')
    ax[0].set_ylabel('Pr√©cision de Validation')
    ax[0].grid(True, alpha=0.3, axis='y')
    
    # Exp√©rience 2
    stats_exp2['mean'].plot(kind='bar', ax=ax[1], yerr=stats_exp2['std'], capsize=5, alpha=0.8)
    ax[1].set_title('Couches Encodeur\n(Moyenne ¬± √âcart-type)')
    ax[1].set_xlabel('Nombre de Couches')
    ax[1].set_ylabel('Pr√©cision de Validation')
    ax[1].grid(True, alpha=0.3, axis='y')
    
    # Exp√©rience 3
    stats_exp3['mean'].plot(kind='bar', ax=ax[2], yerr=stats_exp3['std'], capsize=5, alpha=0.8)
    ax[2].set_title('Couches D√©codeur\n(Moyenne ¬± √âcart-type)')
    ax[2].set_xlabel('Nombre de Couches')
    ax[2].set_ylabel('Pr√©cision de Validation')
    ax[2].grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(os.path.join(results_dir, 'comparison_summary.png'), dpi=150)
    plt.close()
    
    print("\n‚úÖ R√©sum√© comparatif sauvegard√©!")


# =============================================================================
# Fonction Principale
# =============================================================================

def main():
    """
    Fonction principale pour ex√©cuter toutes les exp√©riences
    """
    print("="*80)
    print("COMPARAISON D'HYPERPARAM√àTRES - TRANSFORMER ENCODEUR-D√âCODEUR CSI")
    print("="*80)
    print(f"D√©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Configuration
    base_config = ExperimentConfig()
    
    # Cr√©er le r√©pertoire de r√©sultats
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_dir = f'results_hyperparameter_comparison_{timestamp}'
    os.makedirs(results_dir, exist_ok=True)
    
    print(f"\nüìÅ R√©sultats seront sauvegard√©s dans: {results_dir}")
    
    # Chemin vers les donn√©es
    data_dir = "/Users/bealquentin/Documents/CSI-HAR-Dataset "
    
    # Charger les donn√©es
    print("\nüì• Chargement des donn√©es...")
    X, y, label_encoder = load_csi_data(data_dir, base_config.ACTIVITIES, base_config.SEQUENCE_LENGTH)
    
    # Pr√©traitement
    print("üîß Pr√©traitement des donn√©es...")
    X = preprocess_csi_data(X)
    
    # Mettre √† jour la configuration selon les donn√©es
    base_config.NUM_FEATURES = X.shape[2]
    base_config.SEQUENCE_LENGTH = X.shape[1]
    
    print(f"  ‚îú‚îÄ Shape des donn√©es: {X.shape}")
    print(f"  ‚îú‚îÄ Nombre de classes: {len(np.unique(y))}")
    print(f"  ‚îî‚îÄ Features par s√©quence: {X.shape[2]}")
    
    # Division train/val/test (on garde seulement train et val pour les exp√©riences)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    
    print(f"\nüìä Division des donn√©es:")
    print(f"  ‚îú‚îÄ Train: {X_train.shape[0]} √©chantillons")
    print(f"  ‚îú‚îÄ Validation: {X_val.shape[0]} √©chantillons")
    print(f"  ‚îî‚îÄ Test: {X_test.shape[0]} √©chantillons (non utilis√© dans ces exp√©riences)")
    
    # Lancer les exp√©riences
    all_results = {}
    
    # Exp√©rience 1: T√™tes d'attention
    results_exp1 = experiment_attention_heads(base_config, X_train, y_train, X_val, y_val, results_dir)
    all_results['attention_heads'] = results_exp1
    analyze_and_visualize_results(
        results_exp1, 
        'experiment_1_attention_heads', 
        'Nombre de T√™tes d\'Attention',
        results_dir
    )
    
    # Exp√©rience 2: Couches encodeur
    results_exp2 = experiment_encoder_layers(base_config, X_train, y_train, X_val, y_val, results_dir)
    all_results['encoder_layers'] = results_exp2
    analyze_and_visualize_results(
        results_exp2, 
        'experiment_2_encoder_layers', 
        'Nombre de Couches Encodeur',
        results_dir
    )
    
    # Exp√©rience 3: Couches d√©codeur
    results_exp3 = experiment_decoder_layers(base_config, X_train, y_train, X_val, y_val, results_dir)
    all_results['decoder_layers'] = results_exp3
    analyze_and_visualize_results(
        results_exp3, 
        'experiment_3_decoder_layers', 
        'Nombre de Couches D√©codeur',
        results_dir
    )
    
    # Cr√©er le r√©sum√© comparatif
    create_comparison_summary(results_dir)
    
    print("\n" + "="*80)
    print("EXP√âRIENCES TERMIN√âES!")
    print("="*80)
    print(f"Fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nüìÅ Tous les r√©sultats sont dans: {results_dir}")
    print("\nFichiers g√©n√©r√©s:")
    print("  ‚îú‚îÄ experiment_1_attention_heads.csv")
    print("  ‚îú‚îÄ experiment_1_attention_heads_statistics.csv")
    print("  ‚îú‚îÄ experiment_1_attention_heads_analysis.png")
    print("  ‚îú‚îÄ experiment_2_encoder_layers.csv")
    print("  ‚îú‚îÄ experiment_2_encoder_layers_statistics.csv")
    print("  ‚îú‚îÄ experiment_2_encoder_layers_analysis.png")
    print("  ‚îú‚îÄ experiment_3_decoder_layers.csv")
    print("  ‚îú‚îÄ experiment_3_decoder_layers_statistics.csv")
    print("  ‚îú‚îÄ experiment_3_decoder_layers_analysis.png")
    print("  ‚îú‚îÄ comparison_summary.png")
    print("  ‚îî‚îÄ summary_report.json")


if __name__ == "__main__":
    main()
